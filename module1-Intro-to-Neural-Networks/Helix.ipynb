{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Helix Dataset\n",
    "\n",
    "This dataset is designed to demonstrate the power of non-linear methods and in particular the power of neural networks. The dataset has three classes: two helixes and one bar. The bar runs thru the center of the two helixes. The dataset was generated using uniform distributions without noise to simplify the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cbe127b16dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def make_helix(n_samples = 1000):\n",
    "    \n",
    "    # Helix \n",
    "    x = np.linspace(0, 8*np.pi,n_samples)\n",
    "    y = np.cos(x) - np.random.normal(loc=0, scale=.5,size=n_samples)\n",
    "    z = np.sin(x) - np.random.normal(loc=0, scale=.5,size=n_samples)\n",
    "    helix = np.column_stack((x,y,z))\n",
    "    \n",
    "    # Helix 2\n",
    "    hx = np.linspace(0, 8*np.pi,n_samples)\n",
    "    hy = np.negative(np.cos(x) - np.random.normal(loc=0, scale=.5,size=n_samples))\n",
    "    hz = np.negative(np.sin(x) - np.random.normal(loc=0, scale=.5,size=n_samples))\n",
    "    helix2 = np.column_stack((hx,hy,hz))    \n",
    "    \n",
    "    # Bar\n",
    "    bx = np.random.uniform(low=0, high=helix.max(),size=helix.shape[0])\n",
    "    by = np.random.normal(loc=0, scale =.1, size=helix.shape[0])\n",
    "    bz = np.random.normal(loc=0, scale =.1, size=helix.shape[0])\n",
    "    \n",
    "    bar= np.column_stack((bx, by, bz))\n",
    "\n",
    "    return helix, helix2, bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "X, h,  bar = make_helix(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "helix = pd.DataFrame(X, columns=['x', 'y', 'z'])\n",
    "helix['target'] = 1\n",
    "helix2 = pd.DataFrame(h, columns=['x', 'y', 'z'])\n",
    "helix2['target'] = 2\n",
    "background = pd.DataFrame(bar, columns=['x', 'y', 'z'])\n",
    "background['target'] = 0\n",
    "\n",
    "df = pd.concat([helix,helix2, background])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df, x='x', y='y', z='z', color='target', symbol='target')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x='x', y='y', color='target', symbol='target')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x='y', y='z', color='target', symbol='target')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning on the Helix\n",
    "\n",
    "Generally speaking linear based methods will fail on this dataset. Tree based methods should work will depending on how the data is split into training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['x','y', 'z']], df['target'], test_size=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr = LogisticRegressionCV(cv=5, multi_class='multinomial')\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test,y_test) # Basically a random guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "dtc.score(X_test, y_test) #It's seperating the helixes from the bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10000, max_depth=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test) #Good Results :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Fairly shallow / simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.init(project=\"doublehelixbar\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "y_train_nn = keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test_nn = keras.utils.to_categorical(y_test, num_classes=3)\n",
    "\n",
    "model.add(Dense(75, activation='relu', input_dim=3))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_nn, epochs=2000, validation_data=(X_test,y_test_nn), shuffle=True, verbose=False, callbacks=[WandbCallback()])\n",
    "\n",
    "model.evaluate(X_test,y_test_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning As Time Serries\n",
    "\n",
    "Here we split the helix data along the x axis instead of using a random sample. This increases the difficulty of generalizing the model to unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "train = df.iloc[:2400]\n",
    "test = df.iloc[2400:]\n",
    "\n",
    "features = ['x', 'y', 'z']\n",
    "X_train, y_train = train[features], train['target']\n",
    "X_test, y_test = test[features], test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr = LogisticRegressionCV(cv=5, multi_class='multinomial')\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test,y_test) # Basically a random guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "dtc.score(X_test, y_test) #It's seperating the helixes from the bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10000, max_depth=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test) # The Struggle is Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"doublehelixbar\")\n",
    "model = Sequential()\n",
    "\n",
    "y_train_nn = keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test_nn = keras.utils.to_categorical(y_test, num_classes=3)\n",
    "\n",
    "model.add(Dense(75, activation='relu', input_dim=3))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_nn, epochs=2000, validation_data=(X_test,y_test_nn), shuffle=True, verbose=False, callbacks=[WandbCallback()])\n",
    "\n",
    "model.evaluate(X_test,y_test_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('jcs_challenge.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s2-nnf"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
